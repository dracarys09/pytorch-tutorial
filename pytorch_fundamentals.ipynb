{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428da147-f637-4ade-9238-d8653a5394f9",
   "metadata": {},
   "source": [
    "## PyTorch Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78feff6a-d68a-409d-b656-2fc1075f24e8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8fa48be-a43a-4749-8c38-82e05c881b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS acceleration is available\n"
     ]
    }
   ],
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    print(\"MPS acceleration is available\")\n",
    "    # mps_device = torch.device(\"mps\")\n",
    "    # Move your model to mps just like any other device\n",
    "    # model = YourFavoriteNet()\n",
    "    # model.to(mps_device)\n",
    "\n",
    "    # Now every call runs on the GPU\n",
    "    # pred = model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aacb7d3-9335-4c8f-a0c8-c7097eed2194",
   "metadata": {},
   "source": [
    "## Introduction to tensors\n",
    "\n",
    "### Creating tensors\n",
    "\n",
    "PyTorch tensors are created using `torch.Tensor()` = https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a721872-dcd3-40d7-91f1-7d4ebd9a6521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "print(scalar)\n",
    "\n",
    "print(scalar.ndim)\n",
    "\n",
    "# Get back python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53400a49-0459-41aa-a79c-087015b67f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "# note that this is a 1 dimensional vector\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adea53f4-227d-4a2c-a10e-0c4f6ea6d519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba0efa7-9817-4d7e-9fa5-24174a3a854f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have a 2x1 element\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3a41426-6998-45d3-82a5-4abfc3e5e495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8,  9],\n",
       "        [ 9, 10, 11],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[7, 8, 9],\n",
    "                       [9, 10, 11],\n",
    "                      [9, 10, 11]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5008f29-f8bb-40a4-8e0d-e7ab24b23c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b170d1e-4257-43fc-bea6-a56608dcdc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "008fef6a-734f-4e9c-a336-4d7bb6b392c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "tensor([ 9, 10])\n"
     ]
    }
   ],
   "source": [
    "# 0-th dimension\n",
    "print(MATRIX[0].shape)\n",
    "\n",
    "# 1-st dimension\n",
    "print(MATRIX[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65328385-2112-4092-bdff-72602eed9c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                      [3, 6, 9], \n",
    "                      [2, 4, 5]]])\n",
    "\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53635ad0-c4a6-4403-ba48-3371847273a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "beabdd4b-457c-4f9d-990c-fb16c5051083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580bb088-dc42-4ecf-9e6b-d3b65e191e43",
   "metadata": {},
   "source": [
    "### Random Tensors\n",
    "\n",
    "Why random tensors?\n",
    "\n",
    "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`\n",
    "\n",
    "Torch random tensors: https://pytorch.org/docs/stable/generated/torch.rand.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66c90b8d-e5c6-4ef8-a2bf-43701bd17152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9886, 0.9730, 0.5639, 0.3581],\n",
       "        [0.5523, 0.6588, 0.1288, 0.8259],\n",
       "        [0.4778, 0.6273, 0.8581, 0.9750]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "# You can also do torch.rand(size=(3, 4))\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d2911e7-d7e2-4eac-932b-4a5a447c35ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b5e88b7-0309-4002-90bc-fd430779f1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b5465af-86a8-4578-b250-45f8d5594045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(3, 224, 224)) # height, width, colour channels (R, G, B)\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8899847f-fe9d-44c4-a6ea-e9dbc7810f0a",
   "metadata": {},
   "source": [
    "### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7199dd2-4778-4142-96d9-8940927ad11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2432b0e-2e58-4f40-a4af-97af043594c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros*random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a22c1a26-b9e6-463b-aa6e-279abbd3b715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_tensor = torch.zeros(size=(3,1))\n",
    "mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db4abefd-7e59-4fdf-baff-2433569de52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_tensor*random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0244fa03-3cbb-4b56-b70a-a5476d7c6073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b322ce97-6b92-4a89-a254-d70c781bdac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe4b1bb-8377-4ae2-888a-6499168bb701",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "79996dba-3035-4b41-8de8-774e50dc8770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/c5_nm34x0vl70w912_lld2vw0000gn/T/ipykernel_35946/1840815090.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  torch.range(0, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.range()\n",
    "torch.range(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3c33e52-e26a-4c55-9571-5657fc941964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e656366c-59d6-4973-8841-ebceff8549e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(0,10)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7592111-8013-4db9-a394-04351f0db638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5, 7, 9])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start=1, end=10, step=2) # end is not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a1bf477d-2ded-4766-b7e0-f6c79efeabaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35438d6-a4c2-40a1-a75a-3f53facebffc",
   "metadata": {},
   "source": [
    "### Tensor datatypes\n",
    "\n",
    "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learning\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "13944120-c02d-4973-957a-b3369ceea679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                                dtype=None, # what datatype is the tensor (e.g. float32 or float16)\n",
    "                                device=None, # cpu (default) or mps (for macs) or cuda (for gpus) \n",
    "                                requires_grad=False) # whether or not to track gradients with this tensor's operations\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1bf8338e-0570-44dd-9efc-6c2fd62b66a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9229dd5f-26fc-4174-944c-ee901286a140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2c56cf6c-f8db-48d0-80d0-183273f93300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0430f2ed-54ea-42d3-bac7-3d5f86b445ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_tensor = torch.tensor([3, 6, 9], dtype=torch.int32)\n",
    "int_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8a0650c1-d697-4323-8138-aead6e014115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * int_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515dd47-6c2a-4196-90db-fd7629dfdfe6",
   "metadata": {},
   "source": [
    "### Getting information from tensors (tensor attributes)\n",
    "\n",
    "1. Tensors not right datatype - to get datatype from a tensor, can use `tensor.dtype`\n",
    "2. Tensors not right shape - to get shape from a tensor, can use `tensor.shape`\n",
    "3. Tensors not on the right device - to get device from a tensor, can use `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ba3bee0b-aedb-4770-8f45-7a0e549214fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4785, 0.9216, 0.2167, 0.0989],\n",
       "        [0.5624, 0.1264, 0.9848, 0.4549],\n",
       "        [0.5788, 0.8020, 0.5880, 0.9379]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5acfd981-6639-4255-94b2-4703563be51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4785, 0.9216, 0.2167, 0.0989],\n",
      "        [0.5624, 0.1264, 0.9848, 0.4549],\n",
      "        [0.5788, 0.8020, 0.5880, 0.9379]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is on : cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about some tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on : {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef5654-d1b0-457b-9c54-f8099fe99e98",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ce1714d9-920d-4388-a26e-797af0316cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "75be9478-853d-49ca-b3dd-e5402993f670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply tensor by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b8a21505-5a43-4bec-8454-ee9f05972682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substract tensor by 10\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "76aad4bf-ecf5-4e34-8686-bb78936ccd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 20, 30])\n",
      "tensor([11, 12, 13])\n",
      "tensor([-9, -8, -7])\n"
     ]
    }
   ],
   "source": [
    "# Try out PyTorch inbuilt functions\n",
    "print(torch.mul(tensor, 10))\n",
    "print(torch.add(tensor, 10))\n",
    "print(torch.sub(tensor, 10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46883c9-e5c2-4f16-84e1-ebb3249f4c0d",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "\n",
    "Two main ways of performing multiplication in neural networks and deep learning:\n",
    "\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)\n",
    "\n",
    "There are two main rules that performing matrix multiplication needs to satisfy:\n",
    "1. The **inner dimensions** must match:\n",
    "* `(3,2) @ (3, 2)` won't work\n",
    "* `(2,3) @ (3,2)` will work\n",
    "* `(3,2) @(2,3)` will work\n",
    "\n",
    "2. The resulting matrix has the shape of the **outer dimensions**:\n",
    "* `(2,3) @ (3,2)` -> `(2,2)`\n",
    "* `(3,2) @ (2,3)` -> `(3,3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8e21eba9-968c-4bcc-9135-b6d8ddb05f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "print(tensor , \"*\", tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b33d1435-7789-4251-bcd5-1f3c4a29f31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor) # 1*1 + 2*2 + 3*3 = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9f0797a4-97e2-4e1e-b698-ac55e5a5aab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.38 ms, sys: 690 µs, total: 2.07 ms\n",
      "Wall time: 1.64 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "49d3cc3d-2f48-475b-a80e-058f63b420ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 316 µs, sys: 208 µs, total: 524 µs\n",
      "Wall time: 372 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor) # same as tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b96fb4-d3f3-4859-be33-983b1bd35059",
   "metadata": {},
   "source": [
    "### One of the most common errors in deep lerarning: shape errors\n",
    "\n",
    "Reference: http://matrixmultiplication.xyz/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "dd546484-6ea7-44b4-a904-0f42d72ba3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([3, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[181], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      7\u001b[0m                         [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m],\n\u001b[1;32m      8\u001b[0m                         [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(tensor_B\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# torch.mm is the same as torch.matmul (it's an alias for writing less code)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                        [3, 4],\n",
    "                        [5, 6]])\n",
    "print(tensor_A.shape)\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                        [8, 11],\n",
    "                        [9, 12]])\n",
    "print(tensor_B.shape)\n",
    "torch.mm(tensor_A, tensor_B) # torch.mm is the same as torch.matmul (it's an alias for writing less code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc661531-4678-473c-92d1-57dd50402395",
   "metadata": {},
   "source": [
    "### To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**\n",
    "A transpose switches the axes or dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a2e07301-ec39-4f1b-843b-374fb0111b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "71ce6937-8f41-40a1-ba92-964ef6772a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "644f72a0-1c0a-4144-9bcf-a9a36b003b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[149, 166, 183],\n",
       "        [166, 185, 204],\n",
       "        [183, 204, 225]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_B, tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a4471cd6-06e4-42ec-89da-cfa28707e034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee552a-b8a4-49d2-92ea-5c0d730e7a9e",
   "metadata": {},
   "source": [
    "## Finding the min, max, mean, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "092e4727-a163-4e42-914b-4899b56dc221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "55c10a24-ced3-4cdd-9e41-668aac4a8649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), <function Tensor.min>)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b05e6e97-a17b-4e8e-ba80-bc15497262cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), <function Tensor.max>)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "73ad886b-662a-4c66-b09d-10d437aa59c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean - note: the torch.mean() function requires a tensor of float32 datatype to work\n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "52ad5e00-d869-45ad-95da-2a3a570d7125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32cd6ef-8b53-44c9-b74a-8f1130e5a8b9",
   "metadata": {},
   "source": [
    "## Finding the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6ba0c869-602b-42ca-9dfe-35de95627f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(9))"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the min/max value\n",
    "# This returns the index position of target tensor where min/max value occurs\n",
    "x.argmin(), x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9d0e22a6-89ab-4c39-8b84-8fa279f70f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(9))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(x), torch.argmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213fb4e2-1bbe-4257-9ba9-990442208df8",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - adds a `1` dimension to a target tensor\n",
    "* Permute - return a view of the input with dimentions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7a502688-d98d-42e7-9fc0-a8d32dd7702b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]), 1)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tensor\n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape, x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "505bd041-cef1-4499-8260-2852fa1eb4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4bd591e5-9ac1-4fbe-b8dc-9fde9ea4e1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(1, 9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "424b4d27-4f88-48c0-8763-7d1ebbbe0385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x (because a view of a tensor shares the same memory as the original input)\n",
    "\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0caefff0-3ab6-4dc2-b8b2-800987b099e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "084a9ceb-4d5a-4f5d-894e-53bcd35495dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.squeeze() - removes all single dimensions from a target tensor\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "38b26673-660f-41cb-ab2d-fabbb8472785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.squeeze(), x_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "1a2ce8c7-dfb4-4a8a-9aa5-bea3affbc768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[5., 2., 3., 4., 5., 6., 7., 8., 9.]]]), torch.Size([1, 1, 9]))"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.unsqueeze() - adds a single dimension to a target tensor at a specific dim\n",
    "x_reshaped.unsqueeze(dim=0), x_reshaped.unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "56a85659-5cca-4800-be9b-174d3485e672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " torch.Size([1, 9]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " torch.Size([9]))"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_squeezed = x_reshaped.squeeze()\n",
    "x_reshaped, x_reshaped.shape, x_squeezed, x_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "58861caa-d9c6-4781-9af4-dceb55c98533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_squeezed.unsqueeze(dim=1), x_squeezed.unsqueeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "9f0f3c5d-666b-44a7-840a-ac58dc0206ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0104,  0.4783,  0.5157, -0.0830, -0.6526],\n",
      "         [ 0.7018, -0.1801, -0.6713, -0.7977, -1.3376],\n",
      "         [-0.2163, -1.4021,  1.1246, -0.5250,  1.0711]],\n",
      "\n",
      "        [[ 0.2214, -0.2374,  0.7189,  0.4869,  1.8059],\n",
      "         [ 0.9074, -1.4215, -0.3504,  0.5282, -0.0888],\n",
      "         [ 0.5158,  1.0846, -0.2615, -0.1300,  0.5549]]])\n",
      "torch.Size([2, 3, 5])\n",
      "tensor([[[ 0.0104,  0.7018, -0.2163],\n",
      "         [ 0.2214,  0.9074,  0.5158]],\n",
      "\n",
      "        [[ 0.4783, -0.1801, -1.4021],\n",
      "         [-0.2374, -1.4215,  1.0846]],\n",
      "\n",
      "        [[ 0.5157, -0.6713,  1.1246],\n",
      "         [ 0.7189, -0.3504, -0.2615]],\n",
      "\n",
      "        [[-0.0830, -0.7977, -0.5250],\n",
      "         [ 0.4869,  0.5282, -0.1300]],\n",
      "\n",
      "        [[-0.6526, -1.3376,  1.0711],\n",
      "         [ 1.8059, -0.0888,  0.5549]]])\n",
      "torch.Size([5, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Permute the dimensions\n",
    "x = torch.randn(2, 3, 5)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(torch.permute(x, (2, 0, 1)))\n",
    "print(torch.permute(x, (2, 0, 1)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b8fdae9e-9c54-47d6-a10a-7e10cf4a5d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([224, 224, 3])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearranges the dimensions of a target tensor in a specific order\n",
    "x_original = torch.rand(size=(224, 224, 3)) # [height, width, color_channels]\n",
    "print(x_original.shape)\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = torch.permute(x_original, (2, 0, 1))# [color_channels, height, width]\n",
    "print(x_permuted.shape)\n",
    "\n",
    "print(x_original.permute(2, 0, 1).shape) # shifts axis 1->1, 1->2, 2->0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6f969-b070-40e1-af9a-abf134230cb8",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors)\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "3b4b50f2-dc26-499f-8cbc-5dd520b32892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "293e1050-f8c1-47c6-bbc5-59bb791a54f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on our new tensor\n",
    "x[0], x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "7e1824bb-8fd2-4062-a8c0-5cf21fdf0e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the middle bracket (dim=1)\n",
    "x[0][0], x[0][0].shape # this is same as x[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "aadc6ad7-5fc2-452d-bbcc-81a5b840e9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), 0, torch.Size([]), 1)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the most inner bracket (last dimension)\n",
    "x[0][0][0], x[0][0][0].ndim, x[0][0][0].shape, x[0][0][0].item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "994a5658-7003-4bb1-9922-5612c387ceb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4, 7]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use \":\" to select \"all\" of a target dimension\n",
    "x[:, :, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "09be1424-74b8-4a31-8555-2c24f062ec7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "707a1f35-28bc-46a6-9bdd-cee992704528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
    "x[0, 0, :] # same as x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "a9d04586-e755-49bd-a36a-58577e8b55cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return 9\n",
    "x[0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "f4fcad1b-4a1e-44a1-951f-6d8aee33f751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index on x to return 3, 6, 9\n",
    "x[0, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752bb320-cca3-49ea-86fe-937009479bc4",
   "metadata": {},
   "source": [
    "## PyTorch tensors & NumPy\n",
    "\n",
    "NumPy is a popular scientific Python numerical computing library.\n",
    "\n",
    "And because of this, PyTorch has functionality to interact with it.\n",
    "\n",
    "* Data in NumPy, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "bdf50547-acf3-4318-bbcc-638b04bb5057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array) # warning: when converting from numpy -> pytorch, pytorch reflects numpy's default datatype of float64 unless specified otherwise.\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "6fc89011-d127-491c-9402-8326a6c970a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "c4fd3385-4650-4696-b192-5556328fc549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1.0, 8.0).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "437258fa-b1b9-467c-840b-e64118f8618e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.float32)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But we can always do as follows:\n",
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "tensor, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "620de578-c745-4c37-b721-7f3aa6c7fe8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of array, what will this do to `tensor`?\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "7e7b19bd-1092-47ab-9883-59925326c802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " torch.Tensor,\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_array = tensor.numpy()\n",
    "tensor, type(tensor), numpy_array, type(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a9aad0b4-8f0b-438f-87a7-bfbe0199a3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 3., 3., 3., 3., 3., 3.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, what happens to `numpy_array`?\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bea690e-f0ae-4142-ab97-2de764a43204",
   "metadata": {},
   "source": [
    "## Reproducibility (trying to take random out of random)\n",
    "\n",
    "In short how a neural network learns:\n",
    "\n",
    "`start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again...`\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**.\n",
    "\n",
    "Essentially what a random seed does is \"flavour\" the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "63cbbfc3-9f0d-41e4-9757-69ee34d2703f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3064, 0.1361, 0.6949, 0.3499],\n",
      "        [0.0385, 0.1982, 0.8112, 0.4088],\n",
      "        [0.8399, 0.9727, 0.8315, 0.8793]])\n",
      "tensor([[0.8436, 0.4455, 0.5673, 0.4110],\n",
      "        [0.4841, 0.7677, 0.8522, 0.4263],\n",
      "        [0.5958, 0.0340, 0.1283, 0.7283]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "da5e425b-d361-4e62-88ab-c6c4ecde0de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensors\n",
    "# Set the random seed\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52d317a-2f2b-4f78-8106-c5a7919a1c85",
   "metadata": {},
   "source": [
    "## Extra resources on reproducibility\n",
    "* https://pytorch.org/docs/stable/notes/randomness.html\n",
    "* https://en.wikipedia.org/wiki/Random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5b93b5-8cc7-4c8c-9da3-cb95128d2d80",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch objects on the GPUs (and making faster computations)\n",
    "\n",
    "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes to make everything hunky dory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7619fd87-affe-4d75-80b2-a486ee09023e",
   "metadata": {},
   "source": [
    "### 1. Getting a GPU\n",
    "\n",
    "1. Easiest - use Google Colab for a free GPU (options to upgrade as well)\n",
    "2. Use your own GPU - takes a little bit of setup and requires the investment of purchasing a GPU, there's a lot of options (See this post for options: https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/)\n",
    "3. Use cloud computing - GCP, AWS, Azure, these services allow you to rent computers on the cloud and access them\n",
    "\n",
    "For 2, 3, PyTorch + GPU drivers (CUDA) takes a little bit of setting up, to do this, refer PyTorch setup documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd6c30-ac0e-48d0-932e-e7b41bd9a5a5",
   "metadata": {},
   "source": [
    "### 2. Check for GPU access with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "75a20dfc-d816-4f44-b69d-f86de8e252ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU access with PyTorch\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "1c844832-174e-48ce-afed-9c740c1016ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "7d0abe09-a375-4bb9-920a-6f9840bee4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a706500b-8471-49fd-a126-a4e6d965474c",
   "metadata": {},
   "source": [
    "## 3. Putting tensors (and models) on the GPU\n",
    "\n",
    "The reason we want our tensors/models on the GPU is because using a GPU results in faster computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "e9c8962e-8344-4dd1-9189-3ec29f550cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default on the CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "60ba45f3-b8ca-4721-8933-bbb529eec5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0')"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4bc6b3-f8e5-44a0-9159-0d02af145a92",
   "metadata": {},
   "source": [
    "### 4. Moving tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "802ca8dc-1ee5-42c5-9196-7c3a6387c0d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[397], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# If tensor is on GPU, can't transform it to NumPy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "07947741-4616-469a-b3e0-17a0ae189569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fix the GPU tensor with NumPy issue, we can first set it to the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "a6587f0b-25f5-4039-bf0c-7f16b5c66c67",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, mps:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[412], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, mps:0 and cpu!"
     ]
    }
   ],
   "source": [
    "tensor_on_gpu * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec0e7e-f052-4203-970f-bad82737136e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
